
@{
    ViewData["Title"] = "History";
}

  <div class="container-fluid" style="margin-top:25px">
    <h1 class="text-center">Начальный этап развития средств распределенного управления</h1>

  </div>
  <div class="container-fluid"style="margin-top:35px;padding-right:15px;padding-left:20px">
      <div class="col-12 text-break text-start">
          <h6 align="justify">
          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Впервые парадигма распределенного управления сетями коммутации пакетов, 
          получившая сегодня массовое распространение, была описана в 1974 году (В. Серф, К. Кан) [1] и реализовывалась единым модулем Transmission Control Programm, 
          который объединял в себе функции контроля соединений на уровне точка-точка и обеспечивал передачу датаграмм между отдельными узлами сети.
          Однако объем и сложность функций, которые должен был выполнять этот модуль, быстро росли, поэтому модуль был разделен на две части. <br>
          Одна часть выполняла функции по трансляции датаграмм между форматами локальных сетей и их передаче на сетевом уровне – протокол IP (Internet Protocol), 
          вторая часть контролировала соединение на уровне точка-точка – протокол TCP (Transmission Control Protocol) [2].<br>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Дальнейшее развитие сетевых приложений и аппаратного обеспечения привело к созданию как прикладных протоколов, так и протоколов более низких уровней и, в целом,
к развитию так называемого стека протоколов, который по сложившейся исторически традицией именуют TCP/IP. При этом в процессе развития сетей определилась иерархия сетевых протоколов
, которая в рамках модели архитектуры стека протоколов OSI приобрела и до настоящего времени сохраняет «форму песочных часов».<br>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;На ее верхнем прикладном уровне расположены несколько десятков протоколов, соответствующих современным приложениям (например, http – протокол передачи страниц гипертекста,
smtp – протокол передачи электронной почты, ftp протокол передачи файлов и др.), на нижних уровнях иерархии расположены протоколы организации локальных сетей и протоколы 
физического уровня, описывающие алгоритмы разделения и использования непосредственных носителей сигнала (например, протоколы семейства IEEE 802.11).<br> 
Однако, на транспортном уровне используются два протокола – TCP и UDP (User Datagramm Protocol) [3], которые контролируют соединения на уровне точка–точка, 
то есть на всем сетевом маршруте от отправителя к получателю. Если протокол UDP выполняет ограниченный набор функций, то протокол TCP реализует широкий ряд алгоритмов и является,
по существу, единственным программным комплексом, который реализует функции распределенного управления ресурсами сетевой инфраструктуры, контролируя их загрузку, 
справедливость разделения ресурсов между соединениями, поддерживает связность сети и предоставляет гарантии доставки данных класса best effort.<br>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Первый этап развития протокола TCP после выделения его в отдельный модуль начался в середине 80-х годов, когда в 1984 году впервые был предсказан, 
а в октябре 1986 впервые наблюдался так называемый коллапс перегрузки (congestion collapse) [4]. А именно, наблюдалось явление, когда в сети NSF-net
полезная пропускная способность соединения снизилась с 32Kbit/s до 40bit/s при полностью исправном оборудовании. Соединение было установлено между ЭВМ, 
расположенными в LBL и UC Berkley на расстоянии пятисот метров, и управлялось реализацией TCP операционной системы (OC) Free BSD версии 4.3.<br>
Причина деградации пропускной способности состояла в том, что из-за перегрузки магистрального маршрутизатора некоторые TCPсегменты были потеряны. 
Затем эти сегменты в рамках механизма контроля доставки были отправлены повторно вместе с новыми порциями данных, которые в свою очередь также были потеряны на маршрутизаторе.
Таким образом, сеть заполнилась повторно передаваемыми потерянными данными, которые также в свою очередь терялись, при этом каналы связи были полностью загружены,
магистральный маршрутизатор перегружен, но новые данные не поступали в сеть.<br>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Для решения этой проблемы В. Якобсоном [4] были предложены ряд методов и алгоритмов, которые в дальнейшем стали известны под общим названием контроль перегрузки (Congestion Control).
Наиболее значимыми среди них были алгоритм медленного старта, который зондировал предел доступных ресурсов сетевого маршрута, и алгоритм предотвращения перегрузки. 
Также были усовершенствованы методы оценки характеристик времени кругового оборота (ВКО, англоязычный термин Round Trip Time или RTT) и разработан метод идентификации 
потерянных данных в условиях, когда сведения об их потере, отправленные получателем, также были утеряны на сетевом маршруте. Именно в этой работе была высказана идея о 
наличии обратной связи между поведением отправителя данных и пропускной способностью соединения и предложено считать потерю данных сигналом обратной связи,
характеризующим состояние сетевого маршрута. Все эти предложения были реализованы в 1988 году в новой версии протокола TCP, SunOS версии 4.1.3,4.1.4 (Tahoe).<br>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Однако в ходе эксплуатации версии TCP Tahoe возникла необходимость увеличить ее пропускную способность, так как после идентификации потери данных протокол прекращал
передачу данных, используя алгоритм случайной отсрочки, затем снова входил в алгоритм медленного старта для зондирования нового предела доступных ресурсов сети.
В рамках дальнейшего развития алгоритмов контроля перегрузки в 1990 году в очередном выпуске ОС BSD 4.3 впервые была реализована новая версия алгоритма предотвращения перегрузки,
которую сегодня принято называть TCP Reno (М. Алман, В. Паксон, У. Стивенс) [5].<br>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Здесь события потерь данных разделялись на два класса – те, которые идентифицируются по номерам подтверждений получателя, полученным для других сегментов,
и те, для которых подтверждение не было получено вовсе. Предполагалось, что если подтверждения получателя не доходят до отправителя вовсе, то сеть испытывает более
серьезную перегрузку, чем если данные теряются, но сведения об их доставке или потере доходят до отправителя. В случае потери, определенной по подтверждениям,
TCP уменьшал вдвое скорость отправки данных и продолжал алгоритм предотвращения перегрузки с новыми значениями, во втором случае, следуя версии Tahoe, прекращал передачу 
данных и затем снова начинал зондирование сети с помощью алгоритма медленного старта. Эта модификация позволила существенно увеличить производительность TCP, не подвергая 
при этом риску целостность сети.<br>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Следующая модификация также была направлена на повышение производительности алгоритма предотвращения перегрузки и определяла «событие потерь», как потери нескольких сегментов данных,
идентифицированных в течение одного раунда отправителя, то есть при одном и том же размере скользящего окна. Протокол TCP Reno, в случае групповых потерь уменьшал размер скользящего
окна в 2n раз, где n – число потерянных в раунде сегментов TCP. Теперь при обнаружении «события потерь» размер скользящего окна всегда уменьшался только в два раза.
(С. Флойд, Т. Хендерсон). Новый протокол получил название NewReno [6].<br>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Необходимо отметить, что параллельно с развитием алгоритмов распределенного управления шло развитие алгоритмов идентификации и повторной отправки потерянных данных.
Так в первых версиях TCP использовались кумулятивные подтверждения, в которых получатель сообщал отправителю наибольший номер непрерывной последовательности сегментов.
Недостаток этого подхода состоит в том, что отправитель не может получить сведения о данных, успешно доставленных после разрыва последовательности, вследствие чего вынужден 
повторно отправлять все сегменты, номера которых больше последнего подтвержденного. В 1996 году [7] впервые был предложен механизм выборочных подтверждений SACK (Selective 
acknowlegement), который также повысил производительность протокола и позволил несколько сократить нагрузку на сеть. Этот механизм реализован как опция, начиная с версии Reno
и до настоящего времени. Алгоритмы повторной отправки данных также развивались, преследуя при этом две основные цели: сохранять производительность протокола с одной стороны и
поддерживать целостность доставляемых данных с другой. Здесь нужно отметить алгоритмы быстрой повторной передачи и быстрого восстановления.<br>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Все перечисленных выше алгоритмы и механизмы не только эффективно функционировали, но и поддерживали связность и целостность глобальной сети в условиях ее экспоненциального роста в течение, практически, двух десятилетий. В частности, RFC2581, содержащий описание основных элементов TCP Reno, имел статус действующего стандарта Интернет с 1999 до 2009 года, когда был заменен стандартом RFC5681 [8]. Последний наследует все ключевые парадигмы и методы [5], но предоставляет большую свободу разработчикам реализаций.

Параллельно с основной линией стандартных протоколов популярность получила версия TCP Vegas 1994 (Л. Бракмо, Л. Петерсон), которая не имеет статус стандарта, однако была реализована в некоторых операционных системах, включая последние версии ОС Linux. Сохраняя основную идеологию: зондирование доступного уровня мощности с последующим предотвращением перегрузки, алгоритмы TCP Vegas в качестве сигналов обратной связи использовали не факт потери данных, а результаты анализа последовательности значений времени кругового оборота, наблюдаемого отправителем [9]. Авторами протокола предполагалось, что рост времени кругового оборота происходит за счет увеличения задержек в очередях маршрутизаторов и, следовательно, означает приближение перегрузки сети. Таким образом, TCP Vegas идентифицировал перегрузку раньше, чем происходила потеря, и заранее снижал размер скользящего окна, используя аддитивный, а не мультипликативный метод. Кроме того, чтобы избежать осцилляций пропускной способности, свойственных TCP Reno, протокол строил оценки максимально доступной пропускной способности маршрута, которую и поддерживал через размер скользящего окна. Такая оценка строилась на основании минимального ВКО, наблюдаемого отправителем, и, следовательно, на загруженных маршрутах была завышенной. Кроме этого Vegas проигрывал конкуренцию Reno, так как, разделяя с Reno общий сетевой маршрут, определял перегрузку раньше и снижал пропускную способность, после чего Reno захватывал освободившуюся мощность. Однако достоинства TCP Vegas и ряд высказанных его авторами идей способствую продолжению исследований в этом направлении.
          </h6>
      </div>
  </div>